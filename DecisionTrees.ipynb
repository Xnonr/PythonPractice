{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986da639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Originally based off of the tutorial 'Machine Learn with Python: Decision Trees' by Frederick Nwanganga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc763f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Dependency Importation\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210830ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c70b1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca5030f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the original raw data into a DataFrame\n",
    "data = pd.read_csv('data.csv')\n",
    "\n",
    "# Isolates the dependent variable being solved for\n",
    "y = data[['dependent_variable']]\n",
    "\n",
    "# Isolates the independent variables used to solve for the dependent variable\n",
    "x = data[['independent_variable']]\n",
    "\n",
    "# Splits the original raw data respectively into its training and testing portions\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, \n",
    "    train_size = 0.8, \n",
    "    \n",
    "    # Data to be split using stratified random sampling based on\n",
    "    #    the values of the given column variable\n",
    "    # Stratified random sampling is a sampling method in which a population group is divided into 1 or many\n",
    "    #    distinc units, called strata, based on shared behavior or characteristics\n",
    "    \n",
    "    stratify = y, \n",
    "    \n",
    "    # Seed for result replication\n",
    "    random_state = 1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418a299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the classifier on which the classification oriented Decision Tree model will be based upon\n",
    "classifier = DecisionTreeClassifier(random_state = 1234)\n",
    "\n",
    "# Generates the classification oriented Decision Tree\n",
    "model = classifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c709d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f31d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluates the Decision Tree upon the training portion of the original raw data\n",
    "print(f'Training Accuracy: {model.score(x_train, y_train)}')\n",
    "\n",
    "# Evaluates the Decision Tree upon the testing portion of the original raw data\n",
    "print(f'Testing Accuracy: {model.score(x_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad8f741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba08513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizes the classification oriented Decision Tree\n",
    "plt.figure(figsize = (15, 15))\n",
    "tree.plot_tree(model, \n",
    "               feature_names = list(x.columns), \n",
    "               class_names = ['No', 'Yes'], \n",
    "               filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4186d808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolates the importance of the classification oriented Decision Tree's features\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.Series(importance, index = x.columns)\n",
    "\n",
    "# Visualizes the importance of the classification oriented Decision Tree's features\n",
    "feature_importance.plot(kind = 'bar')\n",
    "plt.ylabel('Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PrePruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd460527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A selection of hyperparameter values utlized for pre-prunning of the classification oriented Decision Tree\n",
    "grid = {\n",
    "    # How many levels deep a Decision Tree is allowed to be\n",
    "    'max_depth': [2, 3, 4, 5],\n",
    "    \n",
    "    # The minimum number of items a Decision Tree must have available to itself before it is allowed to parition \n",
    "    #    and split thereby creating new branches; studies suggest values between 1 and 40 are best\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    \n",
    "    # The minimum number of items allowed to be represented by a Decision Tree's singular leaf node;\n",
    "    #    studies suggest values between 1 and 20 are best\n",
    "    'min_samples_leaf': [1, 2, 3, 4, 5, 6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9f34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search utilized to test via brute force various hyperparameter combinations\n",
    "gcv = GridSearchCV(estimator = classifier, param_grid = grid)\n",
    "gcv.fit(x_train, y_train)\n",
    "\n",
    "# Returns the best hyperparameter combination that maximizes the classification oriented \n",
    "#    decision tree model's accuracy\n",
    "model_ = gcv.best_estimator_\n",
    "\n",
    "model_.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962c34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344b220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only those steps or phases different from the above example are included below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e876ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                    train_size = 0.8, \n",
    "                                                    stratify = x['variable'], \n",
    "                                                    random_state = 1234)\n",
    "\n",
    "# Dummy variables generated from column variables that are qualitative in nature\n",
    "x_train = pd.get_dummies(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3bfd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c57d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the classifier on which the regression oriented Decision Tree model will be based upon\n",
    "regressor = DecisionTreeRegressor(random_state = 1234)\n",
    "\n",
    "# Generates the regression oriented Decision Tree\n",
    "model = regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8686e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e63fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to evaluation the regression oriented Decision Tree, the test predictions must be saved in order\n",
    "#    to then compare them with the actual test results via the mean absolute error\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Going forward, results' values should be expected to be off the mark by + or - the MSE\n",
    "print(f'Mean ABsolute Error (MSE): {mean_absolute_error(y_test, y_test_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81ec3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The higher a datanode is placed within the decision tree, the greater importance said associated variable\n",
    "#    is to the overall model's predictive abilities\n",
    "tree.plot_tree(model, \n",
    "               feature_names = list(x_train.columns),  \n",
    "               filled = True, \n",
    "               max_depth = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47a9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolates the importance of the regression oriented Decision Tree's features\n",
    "importance = model.feature_importances_\n",
    "feature_importance = pd.Series(importance, index = x_train.columns)\n",
    "\n",
    "# Visualizes the importance of the classification oriented Decision Tree's features\n",
    "feature_importance.sort_values().plot(kind = 'bar')\n",
    "plt.ylabel('Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3c14df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PostPruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8440f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost Complexity Prunning involves finding the best Alpha parameter that performs the best with the testing data\n",
    "path = regressor.cost_complexity_pruning_path(x_train, y_train)\n",
    "\n",
    "# Extracts the list of effective alphas from the Decision Tree Regressor\n",
    "ccp_alphas = path.ccp_alphas\n",
    "\n",
    "# The larger the effective Alpha, the smaller and shallower the Decision Tree will be\n",
    "# Removes the largest Alpha, as this results in a Decision Tree of only 1 node\n",
    "ccp_alphas = ccp_alphas[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f06a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "# In order to determine the best Alpha, similar to hyperparameter tuning the models have to be run via a brute\n",
    "#    force methodology in order to determine which returns the best results in terms of score and accuracy\n",
    "for alpha in ccp_alphas:\n",
    "    regressor = DecisionTreeRegressor(random_state = 1234, ccp_alpha = alpha)\n",
    "    model_ = regressor_.fit(x_train, y_train)\n",
    "    train_scores.append(model_.score(x_train, y_train))\n",
    "    test_scores.append(model_.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719727db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizes the effects of various Alpha values on the training and testing datasets\n",
    "plt.plot(ccp_alphas, \n",
    "         train_scores,\n",
    "         marker = 'o', \n",
    "         label = 'train_score', \n",
    "         drawstyle = 'steps_post')\n",
    "\n",
    "plt.plot(ccp_alphas, \n",
    "         test_scores,\n",
    "         marker = 'o', \n",
    "         label = 'test_score', \n",
    "         drawstyle = 'steps_post')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('R-squared by Alpha')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8109756f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the index of the highest test score to then determine the best Alpha value\n",
    "index = test_scores.index(max(test_scores))\n",
    "best_alpha = ccp_alphas[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd3307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits a regression oriented Decision Tree post pruned utilizing the now known best alpha\n",
    "regressor = DecisionTreeRegressor(random_state = 1234, ccp_aplha = best_alpha)\n",
    "\n",
    "model_ = regressor_.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
